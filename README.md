# ğŸ” NGram-DetectGPT: AI Text Detection using N-Gram Delta Features

This project implements a robust detection pipeline to distinguish AI-generated text from human-written content using classical n-gram language models (KenLM) and perturbation-based delta features. It includes paraphrase generation, n-gram scoring, feature extraction, classifier training, evaluation, and result visualization.

---

## ğŸ“ Repository Structure
Ngram_DetectGPT/
â”œâ”€â”€ generate_variants_chatgpt.py # Paraphrase generation using GPT-4 API
â”œâ”€â”€ extract_features_kenlm.py # Computes n-gram delta features
â”œâ”€â”€ train_classifier.py # Trains XGBoost classifiers
â”œâ”€â”€ eval_results.py # Aggregates and visualizes evaluation metrics
â”œâ”€â”€ length_robustness.py # Plots AUC vs. text length
â”œâ”€â”€ ablation_study.py # Runs feature ablation experiments
â”œâ”€â”€ plot_figures.py # Creates accuracy and AUC plots
â”œâ”€â”€ models/ # Pretrained KenLM models (2-gram to 5-gram)
â”œâ”€â”€ datasets/ # Input CSVs (original texts)
â”œâ”€â”€ output/ # Paraphrased variants per temperature
â”œâ”€â”€ N-gram Scoring/ # Feature CSVs with delta scores
â”œâ”€â”€ results/ # Evaluation metrics, plots, summaries
â””â”€â”€ README.md


---

## ğŸ§° Installation Instructions

### 1. âœ… Clone the Repository

```bash
git clone https://github.com/N-Gram-dev/Ngram_DetectGPT.git
cd Ngram_DetectGPT

2. âœ… Create and Activate Virtual Environment (Optional but Recommended)


python3 -m venv env
source env/bin/activate      # On Windows: env\Scripts\activate

3. âœ… Install Python Dependencies


pip install -r requirements.txt

ğŸ“¦ requirements.txt

pandas
numpy
scipy
nltk
openai
tqdm
kenlm
xgboost
scikit-learn
matplotlib
seaborn


ğŸ“¥ Download Pretrained KenLM Models
You must download 4 pre-trained n-gram models (2-gram to 5-gram) into a folder named models/ in the repo root.

ğŸ“ Source:
ğŸ‘‰ https://huggingface.co/NGramDev/ngram-detect-models

ğŸ§¾ Files to download:
2-gram.arpa.bin

3-gram.arpa.bin

4-gram.arpa.bin

5-gram.arpa.bin

models/
â”œâ”€â”€ 2-gram.arpa.bin
â”œâ”€â”€ 3-gram.arpa.bin
â”œâ”€â”€ 4-gram.arpa.bin
â””â”€â”€ 5-gram.arpa.bin

These binary KenLM files are used for log-likelihood, entropy, and variance-based delta feature extraction.

How to Run the Pipeline
The following scripts should be run in order:

generate_variants_chatgpt.py â€“ Calls OpenAI GPT-4 API to generate 10 paraphrases per sentence at 6 temperatures.

extract_features_kenlm.py â€“ Computes log-probability, entropy, and frequency variance deltas using KenLM models.

train_classifier.py â€“ Trains XGBoost classifiers per dataset/model/temperature using extracted delta features.

eval_results.py â€“ Aggregates performance across all runs and produces summary plots.

plot_figures.py â€“ Plots accuracy, AUC, and distributions across variants.

ablation_study.py â€“ Tests the impact of removing feature groups (log-score, entropy, frequency).

length_robustness.py â€“ Analyzes detection AUC stability across different passage lengths.

ğŸ“‚ Output CSVs, ROC-AUC scores, plots, confusion matrices, and summaries are automatically saved in the results/ folder.


